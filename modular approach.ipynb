{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular approach\n",
    "\n",
    "On this noteboook, we try to add and preprocess our own dataset manually and make our own config\n",
    "\n",
    "\n",
    "https://elitedatascience.com/keras-tutorial-deep-learning-in-python\n",
    "\n",
    "https://medium.com/@mjbhobe/mnist-digits-classification-with-keras-ed6c2374bd0e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "from loguru import logger\n",
    "import tensorflow as tf\n",
    "\n",
    "import argparse\n",
    "import contextlib\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import main\n",
    "import constants\n",
    "import contributivity\n",
    "import multi_partner_learning\n",
    "import scenario\n",
    "import utils\n",
    "from dataset import Dataset\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create custom scenario from mandatory parametters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_params = {\n",
    "    'partners_count': 3,\n",
    "    'epoch_count': 2,                            # Not mandatory\n",
    "    'minibatch_count': 2,                        # Not mandatory\n",
    "    'amounts_per_partner': [0.2, 0.5, 0.3],\n",
    "    'samples_split_option': ['basic', 'random']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every other parametter will be set to its default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = Path(r\"C:\\GitHub\\distributed-learning-contributivity\\experiments\\trash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-04 15:28:22.337 | DEBUG    | scenario:__init__:52 - Dataset selected: mnist\n",
      "2020-08-04 15:28:22.338 | DEBUG    | scenario:__init__:87 - Computation use the full dataset for scenario #1\n",
      "2020-08-04 15:28:22.409 | INFO     | scenario:__init__:279 - ### Description of data scenario configured:\n",
      "2020-08-04 15:28:22.410 | INFO     | scenario:__init__:280 -    Number of partners defined: 3\n",
      "2020-08-04 15:28:22.410 | INFO     | scenario:__init__:281 -    Data distribution scenario chosen: random\n",
      "2020-08-04 15:28:22.411 | INFO     | scenario:__init__:282 -    Multi-partner learning approach: fedavg\n",
      "2020-08-04 15:28:22.411 | INFO     | scenario:__init__:283 -    Weighting option: uniform\n",
      "2020-08-04 15:28:22.412 | INFO     | scenario:__init__:284 -    Iterations parameters: 2 epochs > 2 mini-batches > 8 gradient updates per pass\n",
      "2020-08-04 15:28:22.412 | INFO     | scenario:__init__:290 - ### Data loaded: mnist\n",
      "2020-08-04 15:28:22.413 | INFO     | scenario:__init__:291 -    48000 train data with 48000 labels\n",
      "2020-08-04 15:28:22.413 | INFO     | scenario:__init__:292 -    12000 val data with 12000 labels\n",
      "2020-08-04 15:28:22.414 | INFO     | scenario:__init__:293 -    10000 test data with 10000 labels\n"
     ]
    }
   ],
   "source": [
    "current_scenario = scenario.Scenario(\n",
    "        scenario_params,\n",
    "        experiment_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],  28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_labels(y):\n",
    "    y = np_utils.to_categorical(y, 10)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_model_for_dataset():\n",
    "    model = Sequential()\n",
    "    # add Convolutional layers\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))    \n",
    "    model.add(Flatten())\n",
    "    # Densely connected layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # compile with adam optimizer & categorical_crossentropy loss function\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignate dataset to scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_scenario.dataset = Dataset(\n",
    "    \"my_dataset\",\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    input_shape,\n",
    "    num_classes,\n",
    "    preprocess_dataset_labels,\n",
    "    generate_new_model_for_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_dataset\n"
     ]
    }
   ],
   "source": [
    "# Check Scenario name\n",
    "print(current_scenario.dataset.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_scenario.dataset.train_val_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_scenario.partners_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-04 15:28:23.041 | INFO     | scenario:split_data:534 - ### Splitting data among partners:\n",
      "2020-08-04 15:28:23.042 | INFO     | scenario:split_data:535 -    Simple split performed.\n",
      "2020-08-04 15:28:23.042 | INFO     | scenario:split_data:536 -    Nb of samples split amongst partners: 38880\n",
      "2020-08-04 15:28:23.043 | INFO     | scenario:split_data:538 -    Partner #0: 7776 samples with labels [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "2020-08-04 15:28:23.043 | INFO     | scenario:split_data:538 -    Partner #1: 19440 samples with labels [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "2020-08-04 15:28:23.044 | INFO     | scenario:split_data:538 -    Partner #2: 11664 samples with labels [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "2020-08-04 15:28:23.177 | DEBUG    | scenario:compute_batch_sizes:582 -    Compute batch sizes, partner #0: 486\n",
      "2020-08-04 15:28:23.178 | DEBUG    | scenario:compute_batch_sizes:582 -    Compute batch sizes, partner #1: 1215\n",
      "2020-08-04 15:28:23.178 | DEBUG    | scenario:compute_batch_sizes:582 -    Compute batch sizes, partner #2: 729\n",
      "2020-08-04 15:28:23.179 | DEBUG    | scenario:preprocess_scenarios_data:587 - ## Pre-processing datasets of the scenario for keras CNN:\n",
      "2020-08-04 15:28:23.180 | DEBUG    | scenario:preprocess_scenarios_data:591 -    Central early stopping validation set: done.\n",
      "2020-08-04 15:28:23.180 | DEBUG    | scenario:preprocess_scenarios_data:593 -    Central testset: done.\n",
      "2020-08-04 15:28:23.181 | DEBUG    | scenario:preprocess_scenarios_data:615 -    Partner #0: done.\n",
      "2020-08-04 15:28:23.182 | DEBUG    | scenario:preprocess_scenarios_data:615 -    Partner #1: done.\n",
      "2020-08-04 15:28:23.183 | DEBUG    | scenario:preprocess_scenarios_data:615 -    Partner #2: done.\n",
      "2020-08-04 15:28:23.184 | DEBUG    | multi_partner_learning:__init__:69 - MultiPartnerLearning object instantiated.\n",
      "2020-08-04 15:28:23.184 | INFO     | multi_partner_learning:compute_test_score:135 - ## Training and evaluating model on partners with ids: ['#0', '#1', '#2']\n",
      "2020-08-04 15:28:23.232 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-04 15:28:23.233 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:268 - (fedavg) Very first minibatch of epoch n°0, init new models for each partner\n",
      "2020-08-04 15:28:27.628 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 00/01 > Minibatch 00/01 > Partner id #0 (0/2) > val_acc: 0.58\n",
      "2020-08-04 15:28:28.996 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 00/01 > Minibatch 00/01 > Partner id #1 (1/2) > val_acc: 0.55\n",
      "2020-08-04 15:28:30.074 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 00/01 > Minibatch 00/01 > Partner id #2 (2/2) > val_acc: 0.6\n",
      "2020-08-04 15:28:30.077 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-04 15:28:30.077 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-04 15:28:30.078 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°0, init aggregated model for each partner with models from previous round\n",
      "2020-08-04 15:28:31.149 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 00/01 > Minibatch 01/01 > Partner id #0 (0/2) > val_acc: 0.67\n",
      "2020-08-04 15:28:31.949 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 00/01 > Minibatch 01/01 > Partner id #1 (1/2) > val_acc: 0.73\n",
      "2020-08-04 15:28:32.772 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 00/01 > Minibatch 01/01 > Partner id #2 (2/2) > val_acc: 0.75\n",
      "2020-08-04 15:28:32.775 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-04 15:28:33.063 | INFO     | multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['1.036', '0.730']\n",
      "2020-08-04 15:28:33.064 | DEBUG    | multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-04 15:28:33.064 | DEBUG    | multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-04 15:28:33.123 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-04 15:28:33.124 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°1, init aggregated model for each partner with models from previous round\n",
      "2020-08-04 15:28:34.150 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 01/01 > Minibatch 00/01 > Partner id #0 (0/2) > val_acc: 0.76\n",
      "2020-08-04 15:28:34.975 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 01/01 > Minibatch 00/01 > Partner id #1 (1/2) > val_acc: 0.76\n",
      "2020-08-04 15:28:35.697 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 01/01 > Minibatch 00/01 > Partner id #2 (2/2) > val_acc: 0.76\n",
      "2020-08-04 15:28:35.700 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-04 15:28:35.701 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-04 15:28:35.701 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°1, init aggregated model for each partner with models from previous round\n",
      "2020-08-04 15:28:36.741 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 01/01 > Minibatch 01/01 > Partner id #0 (0/2) > val_acc: 0.76\n",
      "2020-08-04 15:28:37.547 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 01/01 > Minibatch 01/01 > Partner id #1 (1/2) > val_acc: 0.82\n",
      "2020-08-04 15:28:38.407 | DEBUG    | multi_partner_learning:log_collaborative_round_partner_result:502 - Epoch 01/01 > Minibatch 01/01 > Partner id #2 (2/2) > val_acc: 0.78\n",
      "2020-08-04 15:28:38.411 | DEBUG    | multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-04 15:28:38.700 | INFO     | multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.654', '0.798']\n",
      "2020-08-04 15:28:38.700 | DEBUG    | multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-04 15:28:38.701 | DEBUG    | multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-04 15:28:38.701 | INFO     | multi_partner_learning:compute_test_score:200 - ### Evaluating model on test data:\n",
      "2020-08-04 15:28:38.915 | INFO     | multi_partner_learning:compute_test_score:203 -    Model metrics names: ['loss', 'accuracy']\n",
      "2020-08-04 15:28:38.916 | INFO     | multi_partner_learning:compute_test_score:204 -    Model metrics values: ['0.633', '0.807']\n",
      "2020-08-04 15:28:39.067 | INFO     | multi_partner_learning:compute_test_score:212 - Training and evaluation on multiple partners: done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.run_scenario(current_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aggregation_weighting', 'dataset_fraction_per_partner', 'dataset_name',\n",
      "       'epoch_count', 'final_relative_nb_samples',\n",
      "       'gradient_updates_per_pass_count', 'is_early_stopping',\n",
      "       'learning_computation_time_sec', 'minibatch_count',\n",
      "       'mpl_nb_epochs_done', 'mpl_test_score',\n",
      "       'multi_partner_learning_approach', 'nb_samples_used', 'partners_count',\n",
      "       'samples_split_description', 'scenario_name', 'short_scenario_name',\n",
      "       'test_data_samples_count', 'train_data_samples_count', 'random_state',\n",
      "       'scenario_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_results = current_scenario.to_dataframe()\n",
    "df_results[\"random_state\"] = 1\n",
    "df_results[\"scenario_id\"] = 1\n",
    "print(df_results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.807\n",
      "Name: mpl_test_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_results.mpl_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
