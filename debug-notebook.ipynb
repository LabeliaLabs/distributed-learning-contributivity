{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 21:51:27.824 | INFO     | mplc.utils:init_gpu_config:107 - No GPU found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mplc import mpl_utils\n",
    "from mplc import constants\n",
    "from mplc.experiment import Experiment\n",
    "from mplc.scenario import Scenario\n",
    "from mplc.experiment import init_experiment_from_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-28 21:51:28.877 | INFO     | mplc.dataset:shorten_dataset_proportion:83 - We don't use the full dataset: only 20.0%\n",
      "2021-02-28 21:51:28.922 | INFO     | mplc.splitter:split:44 - ### Splitting data among partners:\n",
      "2021-02-28 21:51:28.923 | INFO     | mplc.splitter:split:45 - Train data split:\n",
      "2021-02-28 21:51:30.272 | INFO     | mplc.splitter:split:57 -    Partner #0: 2700 samples with labels [7 8 9]\n",
      "2021-02-28 21:51:30.273 | INFO     | mplc.splitter:split:57 -    Partner #1: 2700 samples with labels [4 5 6 7]\n",
      "2021-02-28 21:51:30.273 | INFO     | mplc.splitter:split:57 -    Partner #2: 2700 samples with labels [2 3 4]\n",
      "2021-02-28 21:51:30.274 | INFO     | mplc.splitter:split:57 -    Partner #3: 2700 samples with labels [0 1 2]\n",
      "2021-02-28 21:51:30.275 | INFO     | mplc.scenario:log_scenario_description:407 - Description of data scenario configured:\n",
      "2021-02-28 21:51:30.275 | INFO     | mplc.scenario:log_scenario_description:408 -    Number of partners defined: 4\n",
      "2021-02-28 21:51:30.275 | INFO     | mplc.scenario:log_scenario_description:409 -    Data distribution scenario chosen: Stratified samples split\n",
      "2021-02-28 21:51:30.275 | INFO     | mplc.scenario:log_scenario_description:410 -    Multi-partner learning approach: ensembling\n",
      "2021-02-28 21:51:30.275 | INFO     | mplc.scenario:log_scenario_description:411 -    Weighting option: data-volume\n",
      "2021-02-28 21:51:30.276 | INFO     | mplc.scenario:log_scenario_description:412 -    Iterations parameters: 4 epochs > 2 mini-batches > 8 gradient updates per pass\n",
      "2021-02-28 21:51:30.276 | INFO     | mplc.scenario:log_scenario_description:418 - Data loaded: mnist\n",
      "2021-02-28 21:51:30.276 | INFO     | mplc.scenario:log_scenario_description:422 -    10800 train data with 10800 labels\n",
      "2021-02-28 21:51:30.276 | INFO     | mplc.scenario:log_scenario_description:425 -    1200 val data with 1200 labels\n",
      "2021-02-28 21:51:30.276 | INFO     | mplc.scenario:log_scenario_description:428 -    10000 test data with 10000 labels\n",
      "2021-02-28 21:51:30.277 | INFO     | mplc.experiment:run:142 - Now running experiment experiment_2021-02-28_21h51\n",
      "2021-02-28 21:51:30.299 | INFO     | mplc.experiment:run:151 - (Experiment experiment_2021-02-28_21h51) Now starting repeat 1/1\n",
      "2021-02-28 21:51:30.301 | INFO     | mplc.experiment:run:156 - (Experiment experiment_2021-02-28_21h51, repeat 1/1) Now running scenario 1/1\n",
      "2021-02-28 21:51:30.302 | INFO     | mplc.splitter:split:44 - ### Splitting data among partners:\n",
      "2021-02-28 21:51:30.303 | INFO     | mplc.splitter:split:45 - Train data split:\n",
      "2021-02-28 21:51:31.632 | INFO     | mplc.splitter:split:57 -    Partner #0: 2700 samples with labels [7 8 9]\n",
      "2021-02-28 21:51:31.633 | INFO     | mplc.splitter:split:57 -    Partner #1: 2700 samples with labels [4 5 6 7]\n",
      "2021-02-28 21:51:31.634 | INFO     | mplc.splitter:split:57 -    Partner #2: 2700 samples with labels [2 3 4]\n",
      "2021-02-28 21:51:31.634 | INFO     | mplc.splitter:split:57 -    Partner #3: 2700 samples with labels [0 1 2]\n",
      "2021-02-28 21:51:31.637 | INFO     | mplc.scenario:log_scenario_description:407 - Description of data scenario configured:\n",
      "2021-02-28 21:51:31.638 | INFO     | mplc.scenario:log_scenario_description:408 -    Number of partners defined: 4\n",
      "2021-02-28 21:51:31.638 | INFO     | mplc.scenario:log_scenario_description:409 -    Data distribution scenario chosen: Stratified samples split\n",
      "2021-02-28 21:51:31.639 | INFO     | mplc.scenario:log_scenario_description:410 -    Multi-partner learning approach: ensembling\n",
      "2021-02-28 21:51:31.639 | INFO     | mplc.scenario:log_scenario_description:411 -    Weighting option: data-volume\n",
      "2021-02-28 21:51:31.640 | INFO     | mplc.scenario:log_scenario_description:412 -    Iterations parameters: 4 epochs > 2 mini-batches > 8 gradient updates per pass\n",
      "2021-02-28 21:51:31.640 | INFO     | mplc.scenario:log_scenario_description:418 - Data loaded: mnist\n",
      "2021-02-28 21:51:31.641 | INFO     | mplc.scenario:log_scenario_description:422 -    10800 train data with 10800 labels\n",
      "2021-02-28 21:51:31.642 | INFO     | mplc.scenario:log_scenario_description:425 -    1200 val data with 1200 labels\n",
      "2021-02-28 21:51:31.643 | INFO     | mplc.scenario:log_scenario_description:428 -    10000 test data with 10000 labels\n",
      "2021-02-28 21:51:34.506 | INFO     | mplc.scenario:run:558 - Now starting running scenario scenario_0_repeat_0_2021-02-28_21h51_6fe\n",
      "2021-02-28 21:51:34.575 | INFO     | mplc.multi_partner_learning:init_model:129 - Init new model\n",
      "2021-02-28 21:51:34.577 | INFO     | mplc.multi_partner_learning:__init__:85 - ## Preparation of model's training on partners with ids: ['#0', '#1', '#2', '#3']\n",
      "2021-02-28 21:51:34.727 | INFO     | mplc.multi_partner_learning:__init__:627 - Init EnsemblePredictionsModel model\n",
      "2021-02-28 21:51:38.659 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 00/03 > Minibatch 00/01 > Partner partner_id #0 (0/3) > val_acc: 0.26\n",
      "2021-02-28 21:51:41.305 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 00/03 > Minibatch 00/01 > Partner partner_id #1 (1/3) > val_acc: 0.34\n",
      "2021-02-28 21:51:43.804 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 00/03 > Minibatch 00/01 > Partner partner_id #2 (2/3) > val_acc: 0.28\n",
      "2021-02-28 21:51:46.260 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 00/03 > Minibatch 00/01 > Partner partner_id #3 (3/3) > val_acc: 0.3\n",
      "2021-02-28 21:51:49.727 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 01/03 > Minibatch 00/01 > Partner partner_id #0 (0/3) > val_acc: 0.28\n",
      "2021-02-28 21:51:52.441 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 01/03 > Minibatch 00/01 > Partner partner_id #1 (1/3) > val_acc: 0.36\n",
      "2021-02-28 21:51:55.326 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 01/03 > Minibatch 00/01 > Partner partner_id #2 (2/3) > val_acc: 0.28\n",
      "2021-02-28 21:51:57.856 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 01/03 > Minibatch 00/01 > Partner partner_id #3 (3/3) > val_acc: 0.29\n",
      "2021-02-28 21:52:01.354 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 02/03 > Minibatch 00/01 > Partner partner_id #0 (0/3) > val_acc: 0.28\n",
      "2021-02-28 21:52:03.848 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 02/03 > Minibatch 00/01 > Partner partner_id #1 (1/3) > val_acc: 0.36\n",
      "2021-02-28 21:52:06.371 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 02/03 > Minibatch 00/01 > Partner partner_id #2 (2/3) > val_acc: 0.29\n",
      "2021-02-28 21:52:09.067 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 02/03 > Minibatch 00/01 > Partner partner_id #3 (3/3) > val_acc: 0.3\n",
      "2021-02-28 21:52:12.443 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 03/03 > Minibatch 00/01 > Partner partner_id #0 (0/3) > val_acc: 0.28\n",
      "2021-02-28 21:52:15.196 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 03/03 > Minibatch 00/01 > Partner partner_id #1 (1/3) > val_acc: 0.37\n",
      "2021-02-28 21:52:17.711 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 03/03 > Minibatch 00/01 > Partner partner_id #2 (2/3) > val_acc: 0.29\n",
      "2021-02-28 21:52:20.269 | INFO     | mplc.multi_partner_learning:log_partner_perf:163 - Epoch 03/03 > Minibatch 00/01 > Partner partner_id #3 (3/3) > val_acc: 0.3\n",
      "2021-02-28 21:52:20.271 | INFO     | mplc.multi_partner_learning:eval_and_log_final_model_test_perf:198 - ### Evaluating model on test data:\n",
      "2021-02-28 21:52:25.208 | INFO     | mplc.multi_partner_learning:eval_and_log_final_model_test_perf:221 -    Model metrics names: ['loss', 'accuracy']\n",
      "2021-02-28 21:52:25.209 | INFO     | mplc.multi_partner_learning:eval_and_log_final_model_test_perf:222 -    Model metrics values: ['1.230', '0.639']\n",
      "2021-02-28 21:52:25.209 | INFO     | mplc.multi_partner_learning:fit:266 - Training and evaluation on multiple partners: done. (50.482 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rgoussault/Library/Python/3.8/lib/python/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9130a14d3a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m exp.add_scenario(Scenario(4, [0.25,0.25,0.25,0.25], epoch_count=4, minibatch_count=2, dataset_name='mnist',samples_split_option=\"stratified\",\n\u001b[1;32m      3\u001b[0m                                    dataset_proportion=0.2, multi_partner_learning_approach=\"ensembling\"))\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/distributed-learning-contributivity/mplc/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mscenario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblank_scenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepeat_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# Save scenario results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/distributed-learning-contributivity/mplc/scenario.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_partner_learning_approach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'main_mpl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# -------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/distributed-learning-contributivity/mplc/multi_partner_learning.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m                     f\"done. ({np.round(self.learning_computation_time, 3)} seconds)\")\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_folder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save the model weights and the history data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/distributed-learning-contributivity/mplc/multi_partner_learning.py\u001b[0m in \u001b[0;36msave_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The path to the save folder is None, history data cannot be saved, nor model weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_final_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/distributed-learning-contributivity/mplc/multi_partner_learning.py\u001b[0m in \u001b[0;36msave_final_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_final_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/distributed-learning-contributivity/mplc/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "exp = Experiment()\n",
    "exp.add_scenario(Scenario(4, [0.25,0.25,0.25,0.25], epoch_count=2, minibatch_count=2, dataset_name='mnist',samples_split_option=\"stratified\",\n",
    "                                   dataset_proportion=0.2, multi_partner_learning_approach=\"ensembling\"))\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.scenarios_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.result.mpl_test_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
